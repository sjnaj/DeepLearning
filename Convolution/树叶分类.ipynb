{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:10:51.320189Z","iopub.execute_input":"2022-05-16T11:10:51.321055Z","iopub.status.idle":"2022-05-16T11:11:45.493085Z","shell.execute_reply.started":"2022-05-16T11:10:51.320956Z","shell.execute_reply":"2022-05-16T11:11:45.491981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils import data\nimport torch.optim as optim\n\nfrom torchvision.io import read_image\nfrom PIL import Image\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision.transforms import ToTensor, Lambda\n\nimport cv2\nfrom matplotlib import pyplot as plt\nimport wandb\n\nfrom d2l import torch as d2l\nimport time\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:45.496363Z","iopub.execute_input":"2022-05-16T11:11:45.496725Z","iopub.status.idle":"2022-05-16T11:11:49.314858Z","shell.execute_reply.started":"2022-05-16T11:11:45.496679Z","shell.execute_reply":"2022-05-16T11:11:49.31372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reset_index(drop=True, inplace=True)\n\nroot=\"../input/d2lclassifyleaves/\"\n\ntest_data = pd.read_csv(root+\"test.csv\")\nall_data = pd.read_csv(root+\"train.csv\")\n# train_data = all_data.sample(n=int(len(all_data)*0.9),ignore_index=True)#随机选取\n# val_data = all_data.sample(n=int(len(all_data)*0.1),ignore_index=True)#ignored_index忽略原来的index，重新生成有序index\n#使用交叉验证，先不分割\n\nall_data=all_data.sample(n=len(all_data),ignore_index=True)#shuffle\nclasses = all_data['label'].unique().tolist()#提取lebel列表\nprint(\"all_data:\",all_data.shape,\"test_data shape:\",test_data.shape,\"\\nlabel size:\", len(classes))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:23:18.480885Z","iopub.execute_input":"2022-05-16T11:23:18.481228Z","iopub.status.idle":"2022-05-16T11:23:18.520651Z","shell.execute_reply.started":"2022-05-16T11:23:18.481184Z","shell.execute_reply":"2022-05-16T11:23:18.519554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):#继承自Dataset\n    def __init__(self, labels, img_dir, mode=None):\n        super().__init__()\n        self.mode=mode\n        self.img_labels =labels\n        self.img_dir = img_dir\n        if mode=='train':\n            preprocess = transforms.Compose([\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),#裁剪留下中央方块\n                        transforms.RandomHorizontalFlip(p=.25),#水平翻转\n                        transforms.RandomVerticalFlip(p=.5),#垂直翻转\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n                            #归一化，数据来自imageNet\n            #pred与eval图片处理一致\n        elif mode=='pred':\n            preprocess = transforms.Compose([\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n        elif mode=='eval':\n            preprocess = transforms.Compose([\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n        self.transform = preprocess\n\n    def __len__(self):\n        return len(self.img_dir)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(root,self.img_dir[idx])\n        with Image.open(img_path) as im:\n            image = im\n            if self.transform:\n                image = self.transform(image)\n            if self.mode!='pred':\n                label = self.img_labels.iloc[idx]\n\n                label =torch.tensor(classes.index(label))#类别字符串转换为下标\n                return image, label\n            else:#pred只有image\n                return image\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.417613Z","iopub.execute_input":"2022-05-16T11:11:49.417953Z","iopub.status.idle":"2022-05-16T11:11:49.432451Z","shell.execute_reply.started":"2022-05-16T11:11:49.417912Z","shell.execute_reply":"2022-05-16T11:11:49.43122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_k_fold_data(k,i,data,bs):#返回DataLoader\n  assert k>1\n  fold_size=data.shape[0]//k\n  test=data.iloc[i*fold_size:(i+1)*fold_size]\n  train=pd.concat([data.iloc[0:i*fold_size],data.iloc[(i+1)*fold_size:data.shape[0]]],ignore_index=True)\n    #注意被连接部分要放在列表里,注意index，不重排会越界\n  train_data=MyDataset(train['label'], train['image'], 'train')\n  test_data=MyDataset(test['label'], test['image'], 'eval')\n  return DataLoader(train_data, batch_size=bs, shuffle=True),DataLoader(test_data,batch_size=bs,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.434107Z","iopub.execute_input":"2022-05-16T11:11:49.434673Z","iopub.status.idle":"2022-05-16T11:11:49.447651Z","shell.execute_reply.started":"2022-05-16T11:11:49.434618Z","shell.execute_reply":"2022-05-16T11:11:49.446438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def k_fold_train(k,all_data,num_epochs,learning_rate,batch_size,weight_decay,device):\n  train_acc_sum,valid_acc_sum=0,0\n  for i in range(k):\n    data=get_k_fold_data(k,i,all_data,batch_size)\n    train_acc,valid_acc=train(net,*data,num_epochs,learning_rate,weight_decay,device)\n    #取最后一个epoch的准确率作为每一折的准确率\n    train_acc_sum+=train_acc\n    valid_acc_sum+=valid_acc\n  return train_acc_sum/k,valid_acc_sum/k#返回每折的平均准确率","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.449711Z","iopub.execute_input":"2022-05-16T11:11:49.450053Z","iopub.status.idle":"2022-05-16T11:11:49.463003Z","shell.execute_reply.started":"2022-05-16T11:11:49.450009Z","shell.execute_reply":"2022-05-16T11:11:49.461844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def k_fold_train_single(k,all_data,num_epochs,learning_rate,batch_size,weight_decay,device):\n    train_acc_sum,valid_acc_sum=0,0\n    data=get_k_fold_data(k,0,all_data,batch_size)\n    train_acc,valid_acc=train(net,*data,num_epochs,learning_rate,weight_decay,device)\n    #取最后一个epoch的准确率作为每一折的准确率\n    train_acc_sum+=train_acc\n    valid_acc_sum+=valid_acc\n    return train_acc_sum/k,valid_acc_sum/k#返回每折的平均准确率\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.464506Z","iopub.execute_input":"2022-05-16T11:11:49.465045Z","iopub.status.idle":"2022-05-16T11:11:49.475503Z","shell.execute_reply.started":"2022-05-16T11:11:49.464997Z","shell.execute_reply":"2022-05-16T11:11:49.474344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_hat, y):\n    \"\"\"计算预测正确的样本数\"\"\"\n\n    if y_hat.shape[0] > 1 and y_hat.shape[1] > 1:  # 二维数组，默认向量是列形式的，不能按行求和\n        y_hat = torch.argmax(y_hat, axis=1)  # 取出最大概率值的下标\n        \n    cmp = y_hat.type(y.dtype) == y  # 布尔矩阵\n    return cmp.sum()#去掉原有的float转换，消耗很大\n\ndef evaluate_accuracy_gpu(net, data_iter, device=None):\n    \"\"\"使用GPU计算模型在数据集上的精度\n    Defined in :numref:`sec_lenet`\"\"\"\n    if isinstance(net, nn.Module):\n        net.eval()  # 设置为评估模式\n        if not device:\n            device = next(iter(net.parameters())).device\n    # 正确预测的数量，总预测的数量\n    metric = d2l.Accumulator(2)\n    with torch.no_grad():\n        for X, y in data_iter:\n            if isinstance(X, list):\n                # BERT微调所需的（之后将介绍）\n                X = [x.to(device) for x in X]\n            else:\n                X = X.to(device)\n            y = y.to(device)\n            metric.add(accuracy(net(X), y), d2l.size(y))\n    return metric[0] / metric[1]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.477352Z","iopub.execute_input":"2022-05-16T11:11:49.477913Z","iopub.status.idle":"2022-05-16T11:11:49.49107Z","shell.execute_reply.started":"2022-05-16T11:11:49.477836Z","shell.execute_reply":"2022-05-16T11:11:49.489829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Accumulator:#Accumulator也需要取消float转换以加速\n    \"\"\"在n个变量上累加\"\"\"\n    def __init__(self, n):\n        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n        self.data = [0.0] * n\n\n    def add(self, *args):\n        self.data = [a + b for a, b in zip(self.data, args)]\n        \n\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.492964Z","iopub.execute_input":"2022-05-16T11:11:49.494823Z","iopub.status.idle":"2022-05-16T11:11:49.506796Z","shell.execute_reply.started":"2022-05-16T11:11:49.494669Z","shell.execute_reply":"2022-05-16T11:11:49.505441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, train_iter, test_iter, num_epochs, lr, weight_dacay,device):\n#     def init_weights(m):\n#         if type(m) == nn.Linear or type(m) == nn.Conv2d:\n#             nn.init.xavier_uniform_(m.weight)\n#     net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n#     （Adam+weight decay）\n    optimizer = torch.optim.Adam(net.parameters(),lr = lr,weight_decay=weight_dacay)\n\n#     optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n    loss = nn.CrossEntropyLoss()\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    for epoch in range(num_epochs):\n        # 训练损失之和，训练准确率之和，样本数\n        metric = Accumulator(3)\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            with torch.no_grad():\n\n                metric.add(X.shape[0]*l,accuracy(y_hat,y), X.shape[0])\n\n            timer.stop()\n            train_l = metric[0] / metric[2]\n            train_acc = metric[1] / metric[2]\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        wandb.log({'train_acc':train_acc,'test_acc':test_acc,'loss':train_l})\n    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n    wandb.finish()\n    return train_acc,test_acc#返回最后一个epoch的准确率","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.511779Z","iopub.execute_input":"2022-05-16T11:11:49.512031Z","iopub.status.idle":"2022-05-16T11:11:49.526907Z","shell.execute_reply.started":"2022-05-16T11:11:49.511993Z","shell.execute_reply":"2022-05-16T11:11:49.525774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import wandb#启动多个记录，本例中只启动第一折的\n# for x in range(10):    \n#     run = wandb.init(reinit=True)    with run:        \n#         for y in range(100):           \n#             run.log({\"metric\": x+y})\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:11:49.52871Z","iopub.execute_input":"2022-05-16T11:11:49.529305Z","iopub.status.idle":"2022-05-16T11:11:49.541879Z","shell.execute_reply.started":"2022-05-16T11:11:49.529242Z","shell.execute_reply":"2022-05-16T11:11:49.540706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs, lr, bs, wd = 20, 1e-3, 128, 1e-4\nk=5\n\nwandb.init()\nnet=models.resnet18(pretrained=True)\nwandb.watch(net)#中止时按上面的按钮，按cell的会导致wandb下次运行前出错,用except关闭更保险\ntry:\n    net.fc = nn.Linear(net.fc.in_features,len(classes))#diao'zh'n\n    k_fold_train_single(k,all_data,num_epochs,lr,bs,weight_decay=wd,device='cuda:0')\nexcept:\n    wandb.finish()\n    raise\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:23:29.761108Z","iopub.execute_input":"2022-05-16T11:23:29.761477Z","iopub.status.idle":"2022-05-16T11:54:51.410634Z","shell.execute_reply.started":"2022-05-16T11:23:29.761443Z","shell.execute_reply":"2022-05-16T11:54:51.409588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, train_iter, test_iter, num_epochs, lr, weight_dacay,device):\n#     def init_weights(m):\n#         if type(m) == nn.Linear or type(m) == nn.Conv2d:\n#             nn.init.xavier_uniform_(m.weight)\n#     net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n#     （Adam+weight decay）\n    optimizer = torch.optim.Adam(net.parameters(),lr = lr,weight_decay=weight_dacay)\n    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,3,2)#间隔递增，使得最后很长一段学习率都是下降状态\n# T_0:学习率第一次回到初始值的epoch位置\n# T_mult:这个控制了学习率变化的速度，平方和递增\n#     optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n    loss = nn.CrossEntropyLoss()\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    max_acc=0\n    for epoch in range(num_epochs):\n        # 训练损失之和，训练准确率之和，样本数\n        metric = Accumulator(3)\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            scheduler.step(epoch + i / num_batches)#使同一个batch里的学习率也不同\n            with torch.no_grad():\n\n                metric.add(X.shape[0]*l,accuracy(y_hat,y), X.shape[0])\n\n            timer.stop()\n            train_l = metric[0] / metric[2]\n            train_acc = metric[1] / metric[2]\n            \n        #scheduler.step()\n\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        if (test_acc-max_acc)>0.01:#保存参数\n            max_acc=test_acc\n            torch.save(net.state_dict(),str(int(max_acc*10000)))\n        wandb.log({'train_acc':train_acc,'test_acc':test_acc,'loss':train_l})\n    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n    wandb.finish()\n    return train_acc,test_acc#返回最后一个epoch的准确率","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:54:51.413407Z","iopub.execute_input":"2022-05-16T11:54:51.413733Z","iopub.status.idle":"2022-05-16T11:54:51.429256Z","shell.execute_reply.started":"2022-05-16T11:54:51.413688Z","shell.execute_reply":"2022-05-16T11:54:51.428336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs, lr, bs, wd = 20, 1e-3, 128, 1e-4\nk=5\n\nwandb.init()\nnet=models.resnet18(pretrained=True)\nwandb.watch(net)#中止时按上面的按钮，按cell的会导致wandb下次运行前出错,用except关闭更保险\ntry:\n    net.fc = nn.Linear(net.fc.in_features,len(classes))#diao'zh'n\n    k_fold_train_single(k,all_data,num_epochs,lr,bs,weight_decay=wd,device='cuda:0')#\nexcept:\n    wandb.finish()\n    raise","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:54:51.431336Z","iopub.execute_input":"2022-05-16T11:54:51.432131Z","iopub.status.idle":"2022-05-16T12:27:23.588773Z","shell.execute_reply.started":"2022-05-16T11:54:51.432087Z","shell.execute_reply":"2022-05-16T12:27:23.587787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(net.state_dict(), '9596')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:15:33.275757Z","iopub.status.idle":"2022-05-16T11:15:33.276371Z","shell.execute_reply.started":"2022-05-16T11:15:33.276013Z","shell.execute_reply":"2022-05-16T11:15:33.276043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-05-16T12:29:05.572215Z","iopub.execute_input":"2022-05-16T12:29:05.573001Z","iopub.status.idle":"2022-05-16T12:29:06.392374Z","shell.execute_reply.started":"2022-05-16T12:29:05.572963Z","shell.execute_reply":"2022-05-16T12:29:06.39136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# net=models.resnet18(pretrained=True)\n# net.fc = nn.Linear(net.fc.in_features,len(classes))#diao'zh'n\n# net.load_state_dict(torch.load('9596'))\nnet.to('cpu')\nnet.eval()#注意设为评估模式\ntest_data = pd.read_csv(root+\"test.csv\")\npred_data=MyDataset(None,test_data['image'], 'pred')#None占位\n\ndata=DataLoader(pred_data,batch_size=128, shuffle=False)\nprint(type(data))\n# submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n# submission.to_csv('submission.csv', index=False)\nclasses=np.array(classes)#使得能够被离散列表下标访问\npred=[]\nfor X in data:\n    Y=torch.argmax(net(X), axis=1)\n    \n    pred.append(classes[list(Y.detach())])\ntest_data['label'] = pd.Series(pred)\nsubmission = pd.concat([test_data['image'], test_data['label']], axis=1)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T12:47:02.819306Z","iopub.execute_input":"2022-05-16T12:47:02.819858Z","iopub.status.idle":"2022-05-16T12:47:02.84535Z","shell.execute_reply.started":"2022-05-16T12:47:02.819822Z","shell.execute_reply":"2022-05-16T12:47:02.844299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-05-16T11:15:33.283304Z","iopub.status.idle":"2022-05-16T11:15:33.284369Z","shell.execute_reply.started":"2022-05-16T11:15:33.284001Z","shell.execute_reply":"2022-05-16T11:15:33.284031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}